{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------- Supervised Learnig Algorithims --------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.    Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a supervised learning algorithm used in machine learning to predict the __probability__ of a binary outcome. A binary outcome is limited to one of two possible outcomes. Examples include yes/no, 0/1 and true/false.\n",
    "\n",
    "Logical regression is used in predictive modeling to analyze large datasets in which one or more independent variables can determine an outcome. The outcome is expressed as a __dichotomous__ variable that has one of two possible outcomes.\n",
    "\n",
    "Essentially, logistic regression works by estimating the mathematical probability that an instance belongs to a specified class -- or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A __dichotomous__ variable is a type of variable that only takes on two possible values.\n",
    "\n",
    "Some examples of dichotomous variables include:\n",
    "\n",
    "    Gender: Male or Female\n",
    "    Coin Flip: Heads or Tails\n",
    "    Property Type: Residential or Commercial\n",
    "    Athlete Status: Professional or Amateur\n",
    "    Exam Results: Pass or Fail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  a) Working and Types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression uses something called the __Sigmoid function__ to map predicted predictions and their probabilities. On a graph, if the estimated probability is greater than a pre-defined acceptance threshold, then the model will predict that the instance belongs to that class. If the estimated probability is less than the pre-defined threshold on the graph, then the model will predict the instance does not belong to the class.\n",
    "\n",
    "In statistics, there are three basic types of logistic regression:\n",
    "\n",
    "__Binary logistic regression__ -- useful for predicting the relationship between a binary dependent variable (Y) and an independent variable (X).\n",
    "\n",
    "__Multinomial logistic regression__ -- useful for making predictions when the dependent variable has two or more discrete outcomes and the order of the outcomes doesn't matter.\n",
    "\n",
    "__Ordinal logistic regression__ -- useful for making predictions when the dependent variable has more than two discrete outcomes and the order of the outcomes has some significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 K-Nearest Neighbor (K-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A k-nearest-neighbor algorithm, often abbreviated k-nn, is an approach to data classification that estimates how likely a data point is to be a member of one group or the other depending on what group the data points nearest to it are in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A __k-nearest-neighbor__ is a data classification algorithm that attempts to determine what group a data point is in by looking at the data points around it.\n",
    "\n",
    "An algorithm, looking at one point on a grid, trying to determine if a point is in group A or B, looks at the states of the points that are near it. The range is __arbitrarily__ determined, but the point is to take a sample of the data. If the majority of the points are in group A, then it is likely that the data point in question will be A rather than B, and vice versa.\n",
    "\n",
    "The k-nearest-neighbor is an example of a \"lazy learner\" algorithm because it does not generate a model of the data set beforehand. The only calculations it makes are when it is asked to poll the data point's neighbors. This makes k-nn very easy to implement for data mining. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.    Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A __support vector machine (SVM)__ is machine learning algorithm that analyzes data for classification and regression analysis. SVM is a supervised learning method that looks at data and sorts it into one of two categories. An SVM outputs a map of the sorted data with the margins between the two as far apart as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  a) Working "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Support vector machine__ is a supervised learning algorithm that sorts data into two categories. It is trained with a series of data already classified into two categories, building the model as it is initially trained. The task of an SVM algorithm is to determine which category a new data point belongs in. This makes SVM a kind of non-binary linear classifier.\n",
    "\n",
    "An SVM algorithm should not only place objects into categories, but have the margins between them on a graph as wide as possible.\n",
    "\n",
    "Some applications of SVM include:\n",
    "\n",
    "    Text and hypertext classification\n",
    "    Image classification\n",
    "    Recognizing handwritten characters\n",
    "    Biological sciences, including protein classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.    Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier is an algorithm that uses __Bayes' theorem__ to classify objects. Naive Bayes classifiers assume strong, or naive, independence between attributes of data points. Popular uses of naive Bayes classifiers include spam filters, text analysis and medical diagnosis. These classifiers are widely used for machine learning because they are simple to implement.\n",
    "\n",
    "Naive Bayes is also known as simple Bayes or independence Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  a) Working "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A __naive Bayes classifier__ uses probability theory to classify data. Naive Bayes classifier algorithms make use of Bayes' theorem. The key insight of Bayes' theorem is that the probability of an event can be adjusted as new data is introduced.\n",
    "\n",
    "__**What makes a naive Bayes classifier naive is its assumption that all attributes of a data point under consideration are independent of each other__** \n",
    "A classifier sorting fruits into apples and oranges would know that apples are red, round and are a certain size, but would not assume all these things at once. Oranges are round too, after all.\n",
    "\n",
    "A naive Bayes classifier is not a single algorithm, but a family of machine learning algorithms that make uses of statistical independence. These algorithms are relatively easy to write and run more efficiently than more complex Bayes algorithms.\n",
    "\n",
    "The most popular application is spam filters. A spam filter looks at email messages for certain key words and puts them in a spam folder if they match.\n",
    "\n",
    "Despite the name, the more data it gets, the more accurate a naive Bayes classifier becomes, such as from a user flagging email messages in an inbox for spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree is a graphical representation of specific decision situations that are used when complex branching occurs in a structured decision process. A decision tree is a predictive model based on a branching series of Boolean tests that use specific facts to make more generalized conclusions.\n",
    "\n",
    "The main components of a decision tree involve decision points represented by nodes, actions and specific choices from a decision point. Each rule within a decision tree is represented by tracing a series of paths from root to node to the next node and so on until an action is reached.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.    a) Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are a popular and powerful tool used for classification and prediction purposes. Decision trees provide a convenient alternative for viewing and managing large sets of business rules, allowing them be translated in a way that allows humans to understand them and apply the rules constraints in a database so that records falling into a specific category are sure to be retrieved.\n",
    "\n",
    "Decision trees generally consist of the following four steps:\n",
    "\n",
    "    Structuring the problem as a tree by creating end nodes of the branches, which are associated with a specific path or scenario along the tree\n",
    "    Assigning subject probabilities to each represented event on the tree\n",
    "    Assigning payoffs for consequences. This could be a specific dollar amount or utility value that is associated with a particular scenario.\n",
    "    Identifying and selecting the appropriate course(s) of action based on analyses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is a consensus algorithm used in supervised machine learning (ML) to solve regression and classification problems. Each random forest is comprised of multiple decision trees that work together as an ensemble to produce one prediction.\n",
    "\n",
    "A decision tree is a logical construct that resembles a flowchart and illustrates a series of if-else statements. An important purpose of using random forest is to compensate for the limitations of decision tree algorithms by mapping multiple trees and using the forest's average output (statistical mean).\n",
    "\n",
    "Random forest algorithms can produce acceptable predictions even if individual trees in the forest have incomplete data. Statistically, increasing the number of trees in the ensemble will correspondingly increase the precision of the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is Regression?\n",
    "\n",
    "__Regression is a statistical method used in finance, investing, and other disciplines that attempts to determine the strength and character of the relationship between one dependent variable (usually denoted by Y) and a series of other variables (known as independent variables)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. a) Explaination "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to describe the philosophy behind the random forest is that since the random trees have some overlap, engineers can build systems to study data redundantly with the various trees and look for trends and patterns that support a given data outcome.\n",
    "\n",
    "For example, if five random trees provide information on the same variable from a subset, and four of them agree, the machine learning algorithm may utilize that “majority vote” to build models based on probabilities. In many different kinds of machine learning, constructs like the random forest can help technological systems to drill down into data and provide more sophisticated analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------- UNSupervised Learnig Algorithims ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means clustering is a simple unsupervised learning algorithm that is used to solve clustering problems. It follows a simple procedure of classifying a given data set into a number of clusters, defined by the letter \"k,\" which is fixed beforehand. The clusters are then positioned as points and all observations or data points are associated with the nearest cluster, computed, adjusted and then the process starts over using the new adjustments until a desired result is reached.\n",
    "\n",
    "K-means clustering has uses in search engines, market segmentation, statistics and even astronomy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. a) Explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means clustering is a method used for clustering analysis, especially in data mining and statistics. It aims to partition a set of observations into a number of clusters (k), resulting in the partitioning of the data into Voronoi cells. It can be considered a method of finding out which group a certain object really belongs to.\n",
    "\n",
    "It is used mainly in statistics and can be applied to almost any branch of study. For example, in marketing, it can be used to group different demographics of people into simple groups that make it easier for marketers to target. Astronomers use it to sift through huge amounts of astronomical data; since they cannot analyze each object one by one, they need a way to statistically find points of interest for observation and investigation.\n",
    "\n",
    "The algorithm:\n",
    "\n",
    "    K points are placed into the object data space representing the initial group of centroids.\n",
    "    Each object or data point is assigned into the closest k.\n",
    "    After all objects are assigned, the positions of the k centroids are recalculated.\n",
    "    Steps 2 and 3 are repeated until the positions of the centroids no longer move.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hierarchical cluster analysis, is an algorithm that groups similar objects into groups called clusters. The endpoint is a set of clusters, where each cluster is distinct from each other cluster, and the objects within each cluster are broadly similar to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------- Reinforcement Learning ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental concepts of Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any reinforcement learning problem includes the following elements:\n",
    "\n",
    "    1.  Agent – the program controlling the object of concern (for instance, a robot).\n",
    "    2.  Environment – this defines the outside world programmatically. Everything the agent(s) interacts with is part of the environment. It’s built for the agent to make it seem like a real-world case. It’s needed to prove the performance of an agent, meaning if it will do well once implemented in a real world application.\n",
    "    3.  Rewards – this gives us a score of how the algorithm performs with respect to the environment. It’s represented as 1 or 0. ‘1’ means that the policy network made the right move, ‘0’ means wrong move. In other words, rewards represent gains and losses.\n",
    "    4.  Policy – the algorithm used by the agent to decide its actions. This is the part that can be model-based or model-free.\n",
    "\n",
    "Every problem that needs an RL solution starts with simulating an environment for the agent. Next, you build a policy network that guides the actions of the agent. The agent can then evaluate the policy if its corresponding action resulted in a gain or a loss.\n",
    "\n",
    "The policy is our main discussion point . Policy can be model-based or model-free. When building, our concern is how to optimize the policy network via policy gradient (PG). \n",
    "\n",
    "PG algorithms directly try to optimize the policy to increase rewards. To understand these algorithms, we must take a look at Markov decision processes (MDP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Markov decision processes / Q-Value / Q-Learning / Deep Q Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__MDP__ is a process with a fixed number of states, and it randomly evolves from one state to another at each step. The probability for it to evolve from state A to state B is fixed.\n",
    "\n",
    "A lot of Reinforcement Learning problems with discrete actions are modeled as __Markov decision processes__, with the agent having no initial clue on the next transition state. The agent also has no idea on the rewarding principle, so it has to explore all possible states to begin to decode how to adjust to a perfect rewarding system. This will lead us to what we call Q Learning.\n",
    "\n",
    "The __Q-Learning algorithm__ is adapted from the Q-Value Iteration algorithm, in a situation where the agent has no prior knowledge of preferred states and rewarding principles. Q-Values can be defined as an optimal estimate of a state-action value in an MDP. \n",
    "\n",
    "It is often said that Q-Learning doesn’t scale well to large (or even medium) MDPs with many states and actions. The solution is to approximate the Q-Value of any state-action pair (s,a). This is called Approximate Q-Learning. \n",
    "\n",
    "DeepMind proposed the use of deep neural networks, which work much better, especially for complex problems – without the use of any feature engineering. A deep neural network used to estimate Q-Values is called a __deep Q-network (DQN)__. Using DQN for approximated Q-learning is called Deep Q-Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Difference Between Model-Based and Model-Free Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a model-based RL environment, the policy is based on the use of a machine learning model. To better understand RL Environments/Systems, what defines the system is the policy network. Knowing fully well that the policy is an algorithm that decides the action of an agent. In this case, when an RL environment or system utilizes the use of machine learning models like random forest, gradient boost, neural networks, and others, such an RL system is model-based. Moreover, this isn’t the case with a model-free RL, such a system has no policy based on the use of machine learning models; its policy is guided by the use of non-ML algorithms. For instance, trying to balance a lever system that ensures perfect stability of the effort and load while on the fulcrum (see fig 1). A simple algorithm can be written to basically, ensure that when load is greater than the effort, the fulcrum moves leftward and if otherwise, it moves right. This kind of system is, model-free because it requires no form of machine learning model to achieve stability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model-free | Model-based |\n",
    "|----|---|\n",
    "|rewards are not accounted for (since this is automated, reward = 1)|rewards are accounted for|\n",
    "|no modelling (no decision policy is required)|modelling is required (policy network)|\n",
    "|this doesn’t require the use of initial states to predict the next state|this requires the use of initial states to predict the next state using the policy network|\n",
    "|the rate  with respect to time is zero|the rate  with respect to time approaches zero\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "daf46d0ca0e9c647ae6ad7f1b787e91034b1187ec2d67301969641925d9f544d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
